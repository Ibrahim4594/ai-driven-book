"use strict";(globalThis.webpackChunkai_driven_book=globalThis.webpackChunkai_driven_book||[]).push([[1968],{4442:(e,t,n)=>{n.d(t,{f:()=>a,A:()=>r});var i=n(6540);const s={mcqContainer:"mcqContainer_aMzE",header:"header_ufij",subtitle:"subtitle_A_xb",scoreCard:"scoreCard_FrpM",scoreBig:"scoreBig_LQ0Z",scorePercentage:"scorePercentage_sCU0",scoreLabel:"scoreLabel_rRZo",questionsList:"questionsList_umTx",questionCard:"questionCard_Wfqx",questionHeader:"questionHeader_UsZJ",questionNumber:"questionNumber_Eicx",correctBadge:"correctBadge_exPB",incorrectBadge:"incorrectBadge__psw",questionText:"questionText_kqM1",optionsList:"optionsList_dCUU",option:"option_z5CR",selected:"selected_UDZP",correct:"correct_wiey",incorrect:"incorrect_zD8a",showCorrect:"showCorrect_uKRT",optionLetter:"optionLetter_H8LO",optionText:"optionText_GLrF",correctIcon:"correctIcon_ruBo",explanation:"explanation_u46W",explanationLabel:"explanationLabel_vf_h",explanationText:"explanationText_t2cW",submitButton:"submitButton_aQgt",actions:"actions_fsw7",submitAllButton:"submitAllButton_V4VJ",retryButton:"retryButton_LySZ"};var o=n(4848);function r({questions:e,title:t="Chapter Quiz"}){const[n,r]=(0,i.useState)(new Array(e.length).fill(-1)),[a,c]=(0,i.useState)(new Array(e.length).fill(!1)),[l,d]=(0,i.useState)(0),[p,u]=(0,i.useState)(!1),h=n.every(e=>-1!==e),m=a.every(e=>e);return(0,o.jsxs)("div",{className:s.mcqContainer,children:[(0,o.jsxs)("div",{className:s.header,children:[(0,o.jsxs)("h3",{children:["\ud83d\udcdd ",t]}),(0,o.jsx)("p",{className:s.subtitle,children:"Test your understanding with these multiple choice questions"}),p&&(0,o.jsxs)("div",{className:s.scoreCard,children:[(0,o.jsxs)("div",{className:s.scoreBig,children:[l,"/",e.length]}),(0,o.jsxs)("div",{className:s.scorePercentage,children:[Math.round(l/e.length*100),"%"]}),(0,o.jsx)("div",{className:s.scoreLabel,children:l===e.length?"\ud83c\udf89 Perfect Score!":l>=.7*e.length?"\u2705 Great Job!":l>=.5*e.length?"\ud83d\udc4d Good Effort!":"\ud83d\udcda Keep Learning!"})]})]}),(0,o.jsx)("div",{className:s.questionsList,children:e.map((t,i)=>(0,o.jsxs)("div",{className:s.questionCard,children:[(0,o.jsxs)("div",{className:s.questionHeader,children:[(0,o.jsxs)("span",{className:s.questionNumber,children:["Question ",i+1]}),a[i]&&(0,o.jsx)("span",{className:t.options[n[i]]?.isCorrect?s.correctBadge:s.incorrectBadge,children:t.options[n[i]]?.isCorrect?"\u2713 Correct":"\u2717 Incorrect"})]}),(0,o.jsx)("div",{className:s.questionText,children:t.question}),(0,o.jsx)("div",{className:s.optionsList,children:t.options.map((e,t)=>{const c=n[i]===t,l=a[i],d=e.isCorrect;let p=s.option;return c&&(p+=` ${s.selected}`),l&&c&&d&&(p+=` ${s.correct}`),l&&c&&!d&&(p+=` ${s.incorrect}`),l&&!c&&d&&(p+=` ${s.showCorrect}`),(0,o.jsxs)("button",{className:p,onClick:()=>((e,t)=>{if(a[e])return;const i=[...n];i[e]=t,r(i)})(i,t),disabled:a[i],children:[(0,o.jsx)("span",{className:s.optionLetter,children:String.fromCharCode(65+t)}),(0,o.jsx)("span",{className:s.optionText,children:e.text}),l&&d&&(0,o.jsx)("span",{className:s.correctIcon,children:"\u2713"})]},t)})}),a[i]&&(0,o.jsxs)("div",{className:s.explanation,children:[(0,o.jsx)("div",{className:s.explanationLabel,children:"\ud83d\udca1 Explanation:"}),(0,o.jsx)("div",{className:s.explanationText,children:t.explanation})]}),!a[i]&&-1!==n[i]&&(0,o.jsx)("button",{className:s.submitButton,onClick:()=>(t=>{const i=[...a];i[t]=!0,c(i);const s=e[t].options[n[t]]?.isCorrect;s&&d(l+1)})(i),children:"Submit Answer"})]},i))}),(0,o.jsxs)("div",{className:s.actions,children:[!m&&(0,o.jsx)("button",{className:s.submitAllButton,onClick:()=>{let t=0;const i=e.map(()=>!0);e.forEach((e,i)=>{-1!==n[i]&&e.options[n[i]].isCorrect&&t++}),c(i),d(t),u(!0)},disabled:!h,children:h?"Submit All Answers":`Answer All Questions (${n.filter(e=>-1!==e).length}/${e.length})`}),m&&(0,o.jsx)("button",{className:s.retryButton,onClick:()=>{r(new Array(e.length).fill(-1)),c(new Array(e.length).fill(!1)),d(0),u(!1)},children:"\ud83d\udd04 Retry Quiz"})]})]})}const a={ch1:[{question:"What is the primary function of the transformer architecture in Large Language Models?",options:[{text:"To compress data for storage",isCorrect:!1},{text:"To use self-attention mechanisms to understand context",isCorrect:!0},{text:"To convert images to text",isCorrect:!1},{text:"To optimize database queries",isCorrect:!1}],explanation:"Transformers use self-attention mechanisms to understand relationships between words in context, allowing LLMs to generate coherent and contextually relevant text."},{question:"What are tokens in the context of LLMs?",options:[{text:"Security credentials for API access",isCorrect:!1},{text:"Basic units of text that LLMs process (words, subwords, or characters)",isCorrect:!0},{text:"Currency used to pay for AI services",isCorrect:!1},{text:"Encryption keys for data security",isCorrect:!1}],explanation:"Tokens are the fundamental units LLMs process. Text is broken down into tokens (which can be words, parts of words, or characters) before being processed by the model."},{question:"What is the difference between fine-tuning and prompt engineering?",options:[{text:"Fine-tuning is cheaper and faster than prompt engineering",isCorrect:!1},{text:"Prompt engineering requires retraining the entire model",isCorrect:!1},{text:"Fine-tuning retrains the model on specific data, while prompt engineering crafts effective instructions",isCorrect:!0},{text:"They are the same thing with different names",isCorrect:!1}],explanation:"Fine-tuning involves retraining an LLM on specialized data (costly and time-consuming), while prompt engineering guides the model through well-crafted instructions without retraining."},{question:"What is a context window in LLMs?",options:[{text:"A graphical user interface for AI tools",isCorrect:!1},{text:"The maximum amount of text an LLM can consider at once",isCorrect:!0},{text:"The time period during which AI generates responses",isCorrect:!1},{text:"The physical window on your screen displaying AI output",isCorrect:!1}],explanation:"A context window is the maximum amount of text (measured in tokens) that an LLM can process simultaneously. Larger context windows allow better understanding of longer documents but increase computational costs."},{question:"Why is AI-driven development transforming software engineering?",options:[{text:"It completely replaces human developers",isCorrect:!1},{text:"It accelerates coding, automates tasks, and allows developers to focus on problem-solving",isCorrect:!0},{text:"It eliminates the need for testing and debugging",isCorrect:!1},{text:"It only works for simple applications",isCorrect:!1}],explanation:"AI-driven development enhances productivity by automating routine tasks, generating code from specifications, and assisting with debugging, allowing developers to focus on high-level design and complex problem-solving."}],ch2:[{question:"What is the main difference between traditional development and AI-driven development?",options:[{text:"AI-driven development doesn't require any coding skills",isCorrect:!1},{text:"AI-driven development uses AI as a pair programmer to assist with coding tasks",isCorrect:!0},{text:"Traditional development is always faster",isCorrect:!1},{text:"AI-driven development can only be used for web applications",isCorrect:!1}],explanation:"AI-driven development leverages AI tools as intelligent assistants that help with code generation, debugging, testing, and documentation, while traditional development relies entirely on manual coding by humans."},{question:"Which of the following is NOT a benefit of AI coding assistants?",options:[{text:"Faster code generation from natural language",isCorrect:!1},{text:"Automated bug detection and testing",isCorrect:!1},{text:"Guaranteed bug-free code every time",isCorrect:!0},{text:"Code review and refactoring suggestions",isCorrect:!1}],explanation:"AI assistants are powerful but not perfect. They can help detect bugs and improve code quality, but they don't guarantee bug-free code. Human review and testing are still essential."},{question:"What is a common pitfall when using AI coding assistants?",options:[{text:"They are too slow to be practical",isCorrect:!1},{text:"Over-relying on AI without understanding the generated code",isCorrect:!0},{text:"They only work with Python",isCorrect:!1},{text:"They require expensive hardware",isCorrect:!1}],explanation:"A major pitfall is blindly accepting AI-generated code without understanding it. This can lead to security vulnerabilities, bugs, and maintainability issues. Always review and test AI-generated code."},{question:"How should developers integrate AI tools into their workflow?",options:[{text:"Use AI to write all code and never review it",isCorrect:!1},{text:"Only use AI for documentation, never for actual code",isCorrect:!1},{text:"Use AI for initial drafts and boilerplate, then review and refine",isCorrect:!0},{text:"Replace all testing with AI-generated tests",isCorrect:!1}],explanation:"Effective integration involves using AI for initial code generation and boilerplate, then applying human expertise to review, test, and refine the output. This combines AI efficiency with human judgment."},{question:"What role does prompt engineering play in AI-driven development?",options:[{text:"It's only useful for chatbots",isCorrect:!1},{text:"It helps developers craft clear instructions to get better AI-generated code",isCorrect:!0},{text:"It's a waste of time compared to traditional coding",isCorrect:!1},{text:"It only works with specific programming languages",isCorrect:!1}],explanation:"Prompt engineering is crucial for AI-driven development. Well-crafted prompts with clear requirements, context, and examples lead to more accurate, maintainable, and useful AI-generated code."}],ch3:[{question:"Which type of AI tool provides inline code suggestions directly in your IDE?",options:[{text:"Chat-based assistants like ChatGPT",isCorrect:!1},{text:"IDE-integrated tools like GitHub Copilot",isCorrect:!0},{text:"CLI tools like Aider",isCorrect:!1},{text:"Specialized platforms like Devin AI",isCorrect:!1}],explanation:"IDE-integrated tools like GitHub Copilot, Cursor, and Tabnine provide real-time inline code suggestions as you type, seamlessly integrating with your development environment."},{question:"What is the main advantage of cloud-based AI models over local models?",options:[{text:"They work without internet connection",isCorrect:!1},{text:"They are completely free to use",isCorrect:!1},{text:"They offer superior performance and regular updates",isCorrect:!0},{text:"They guarantee complete data privacy",isCorrect:!1}],explanation:"Cloud-based models (GPT-4, Claude) provide state-of-the-art performance, large context windows, and regular updates. However, they require internet connectivity and raise privacy considerations."},{question:"When choosing an AI coding tool, which factor is MOST important for large codebases?",options:[{text:"The color scheme of the interface",isCorrect:!1},{text:"Context window size and codebase understanding",isCorrect:!0},{text:"The number of programming languages supported",isCorrect:!1},{text:"The speed of simple autocomplete",isCorrect:!1}],explanation:"For large codebases, context window size is crucial. Tools with larger context windows can understand more of your codebase at once, leading to more relevant and accurate suggestions."},{question:"What distinguishes GitHub Copilot from ChatGPT for coding tasks?",options:[{text:"Copilot requires no API key while ChatGPT does",isCorrect:!1},{text:"Copilot provides inline suggestions in your IDE, ChatGPT offers conversational help",isCorrect:!0},{text:"ChatGPT is always more accurate than Copilot",isCorrect:!1},{text:"Copilot only works with JavaScript",isCorrect:!1}],explanation:"GitHub Copilot integrates directly into your IDE for inline suggestions as you type, while ChatGPT provides conversational assistance for explanations, problem-solving, and refactoring through a chat interface."},{question:"Which AI tool category is best for terminal-based workflows?",options:[{text:"IDE plugins",isCorrect:!1},{text:"Web-based chatbots",isCorrect:!1},{text:"CLI tools like Claude Code or Aider",isCorrect:!0},{text:"Specialized autonomous platforms",isCorrect:!1}],explanation:"CLI tools like Claude Code and Aider are specifically designed for command-line workflows, allowing developers who prefer terminal-based development to leverage AI assistance."}],ch4:[{question:"What is the most important principle of effective prompt engineering?",options:[{text:"Use as few words as possible",isCorrect:!1},{text:"Be specific and provide clear context with examples",isCorrect:!0},{text:"Always use technical jargon",isCorrect:!1},{text:"Never mention edge cases",isCorrect:!1}],explanation:"Effective prompts are specific, provide clear context, include examples, and define constraints. Clarity and detail lead to more accurate AI responses."},{question:"How does Markdown improve prompts for AI coding assistants?",options:[{text:"It makes prompts look prettier but doesn't affect results",isCorrect:!1},{text:"It provides structure through headings, lists, and code blocks",isCorrect:!0},{text:"It encrypts sensitive information in prompts",isCorrect:!1},{text:"It reduces the token count of prompts",isCorrect:!1}],explanation:"Markdown provides structure that makes prompts more readable for both humans and AI. Headings, lists, code blocks, and emphasis help organize requirements and highlight important information."},{question:"What should you include in the context of a prompt?",options:[{text:"Only the immediate task with no background",isCorrect:!1},{text:"Project tech stack, coding standards, existing patterns, and requirements",isCorrect:!0},{text:"Personal information about team members",isCorrect:!1},{text:"Unrelated code from different projects",isCorrect:!1}],explanation:"Good context includes relevant information about your tech stack, coding standards, existing code patterns, user requirements, and constraints. More relevant context leads to better AI suggestions."},{question:"What should you do when AI generates incorrect or suboptimal code?",options:[{text:"Give up and write all code manually",isCorrect:!1},{text:"Use the code anyway without changes",isCorrect:!1},{text:"Refine your prompt with more details and iterate",isCorrect:!0},{text:"Switch to a different programming language",isCorrect:!1}],explanation:"When AI output is poor, refine your prompt with more specific details, provide examples of desired output, point out issues, and iterate. Use AI as a collaborative tool, not a one-shot solution."},{question:"Why is it important to break complex tasks into smaller steps in prompts?",options:[{text:"To confuse the AI model",isCorrect:!1},{text:"To make prompts longer and more impressive",isCorrect:!1},{text:"AI performs better with focused, manageable tasks",isCorrect:!0},{text:"It's not important; always use one giant prompt",isCorrect:!1}],explanation:"Breaking complex tasks into smaller, focused steps helps AI understand each component better, produces more accurate results, and makes debugging easier when issues arise."}],ch5:[{question:"What is the core principle of Specification-Driven Development (SDD)?",options:[{text:"Write code first, then document it",isCorrect:!1},{text:"Write detailed specifications before implementation",isCorrect:!0},{text:"Skip documentation entirely",isCorrect:!1},{text:"Only write specifications for complex features",isCorrect:!1}],explanation:"SDD emphasizes creating clear, detailed specifications before writing any code. These specs serve as contracts between requirements and implementation, especially powerful with AI code generation."},{question:"Which is NOT an essential element of a good specification?",options:[{text:"Context explaining the 'why'",isCorrect:!1},{text:"Functional requirements with details",isCorrect:!1},{text:"The developer's personal preferences",isCorrect:!0},{text:"Success criteria and acceptance tests",isCorrect:!1}],explanation:"A complete specification includes context, objectives, functional requirements, data models, edge cases, non-functional requirements, and success criteria. Personal preferences are not part of specifications."},{question:"How does SDD improve AI-generated code quality?",options:[{text:"It doesn't; AI works the same with or without specs",isCorrect:!1},{text:"It provides comprehensive context and clear acceptance criteria for validation",isCorrect:!0},{text:"It makes the AI generate code faster",isCorrect:!1},{text:"It reduces the need for testing",isCorrect:!1}],explanation:"Detailed specifications provide AI with comprehensive context, clear interfaces, explicit edge cases, and validation criteria, resulting in more accurate and maintainable code."},{question:"What makes SDD specifications different from traditional waterfall documentation?",options:[{text:"SDD specs are never updated after creation",isCorrect:!1},{text:"SDD specs are living documents, executable, and designed for AI consumption",isCorrect:!0},{text:"SDD specs are shorter and less detailed",isCorrect:!1},{text:"There is no difference",isCorrect:!1}],explanation:"Unlike static waterfall docs, SDD specifications are living documents that are continuously updated, executable/testable, and optimized for AI tools to generate code from them."},{question:"What should specifications include regarding edge cases?",options:[{text:"Nothing; edge cases can be figured out during implementation",isCorrect:!1},{text:"Explicit definitions of edge cases and how to handle them",isCorrect:!0},{text:"Only the most common edge case",isCorrect:!1},{text:"A note saying 'handle edge cases appropriately'",isCorrect:!1}],explanation:"Good specifications explicitly define edge cases and specify exactly how they should be handled. This prevents ambiguity and ensures AI-generated code properly addresses all scenarios."}],ch6:[{question:"In Spec-Driven Methodology, when should specifications be reviewed?",options:[{text:"Only after all code is written",isCorrect:!1},{text:"Before AI generates code from them",isCorrect:!0},{text:"Never; specifications don't need review",isCorrect:!1},{text:"Only when bugs are found",isCorrect:!1}],explanation:"Specifications should be reviewed with stakeholders before code generation to ensure alignment, catch issues early, and provide a solid foundation for AI-assisted implementation."},{question:"How should specifications be structured for AI to understand them effectively?",options:[{text:"As free-form text with no structure",isCorrect:!1},{text:"Using structured formats like Markdown or YAML with explicit data types",isCorrect:!0},{text:"As images or diagrams only",isCorrect:!1},{text:"In natural language without any technical details",isCorrect:!1}],explanation:"AI-friendly specs use structured formats (Markdown, YAML), are explicit about data types and constraints, include examples, and avoid ambiguity through consistent terminology."},{question:"Which tool is commonly used for API specifications in Spec-Driven Development?",options:[{text:"Microsoft Word",isCorrect:!1},{text:"OpenAPI/Swagger",isCorrect:!0},{text:"Adobe Photoshop",isCorrect:!1},{text:"Notepad",isCorrect:!1}],explanation:"OpenAPI (formerly Swagger) is the industry standard for API specifications, providing a structured way to define endpoints, request/response formats, and validation rules."},{question:"How do you validate that AI-generated code meets specifications?",options:[{text:"Just trust that the AI got it right",isCorrect:!1},{text:"Use automated tests derived from spec acceptance criteria",isCorrect:!0},{text:"Only check if it compiles",isCorrect:!1},{text:"Validation isn't necessary with AI-generated code",isCorrect:!1}],explanation:"Validation requires automated tests based on acceptance criteria, type checking, API contract testing, code review, and integration tests for edge cases specified in the spec."},{question:"What role do specifications play after code is generated?",options:[{text:"They should be deleted to save space",isCorrect:!1},{text:"They serve as living documentation and are updated as requirements change",isCorrect:!0},{text:"They are archived and never looked at again",isCorrect:!1},{text:"They are only useful during initial development",isCorrect:!1}],explanation:"Specifications remain valuable as living documentation, single source of truth, basis for automated testing, and guides for future changes. They should be updated as requirements evolve."}],ch7:[{question:"What does RAG stand for in AI systems?",options:[{text:"Random Access Generation",isCorrect:!1},{text:"Retrieval-Augmented Generation",isCorrect:!0},{text:"Rapid Application Generator",isCorrect:!1},{text:"Recursive Algorithm Gateway",isCorrect:!1}],explanation:"RAG stands for Retrieval-Augmented Generation. It combines information retrieval (searching documents) with AI generation to provide accurate, context-aware responses based on specific data."},{question:"How do vector embeddings enable semantic search in RAG?",options:[{text:"They compress files to save storage space",isCorrect:!1},{text:"They convert text to numerical vectors that capture meaning",isCorrect:!0},{text:"They translate text between languages",isCorrect:!1},{text:"They encrypt data for security",isCorrect:!1}],explanation:"Vector embeddings convert text into high-dimensional numerical vectors that capture semantic meaning. Similar texts have similar vectors, enabling similarity search for relevant documents."},{question:"Which component stores vector embeddings in a RAG system?",options:[{text:"Traditional SQL database",isCorrect:!1},{text:"Vector database like Qdrant or Pinecone",isCorrect:!0},{text:"Text file on disk",isCorrect:!1},{text:"Browser localStorage",isCorrect:!1}],explanation:"Vector databases like Qdrant, Pinecone, or Weaviate are specifically designed to store and efficiently search through vector embeddings using similarity metrics."},{question:"What is a common challenge in RAG systems?",options:[{text:"They are too simple to be useful",isCorrect:!1},{text:"Poor chunking can lead to lost context",isCorrect:!0},{text:"They never make mistakes",isCorrect:!1},{text:"They only work with English text",isCorrect:!1}],explanation:"Common RAG challenges include poor chunking losing context, irrelevant retrieval, hallucinations despite context, slow performance, and high costs. Solutions include semantic chunking, reranking, and prompt engineering."},{question:"Why is source citation important in RAG chatbots?",options:[{text:"It makes the response longer",isCorrect:!1},{text:"It provides transparency and allows users to verify information",isCorrect:!0},{text:"It's not important; citations are optional",isCorrect:!1},{text:"It confuses users",isCorrect:!1}],explanation:"Source citations provide transparency, allow users to verify information, build trust, and enable them to explore original documents for deeper understanding. They're essential for RAG system credibility."}],ch8:[{question:"What is the first phase of implementing an AI-driven project?",options:[{text:"Deploy to production immediately",isCorrect:!1},{text:"Requirements gathering and specification writing",isCorrect:!0},{text:"Testing and debugging",isCorrect:!1},{text:"Marketing the product",isCorrect:!1}],explanation:"The first phase is gathering requirements and writing clear specifications. This foundation guides all subsequent AI-assisted development, ensuring the generated code meets actual needs."},{question:"What should you do FIRST when debugging AI-generated code?",options:[{text:"Delete all the code and start over",isCorrect:!1},{text:"Read and understand the generated code",isCorrect:!0},{text:"Immediately ask AI to fix it without investigating",isCorrect:!1},{text:"Deploy to production and hope it works",isCorrect:!1}],explanation:"Always read and understand AI-generated code first. Then use traditional debugging tools, check for common AI mistakes, and refine prompts with specific bug details for fixes."},{question:"Which testing strategy is most important for AI-generated code?",options:[{text:"Skip testing since AI code is always perfect",isCorrect:!1},{text:"Only test manually without automation",isCorrect:!1},{text:"Write tests based on specification acceptance criteria",isCorrect:!0},{text:"Just run the code once and assume it works",isCorrect:!1}],explanation:"Tests should be based on specification acceptance criteria, including unit tests for functions, integration tests for components, edge case testing, and validation against requirements."},{question:"How should AI-generated codebases be maintained over time?",options:[{text:"Never update them; AI code doesn't need maintenance",isCorrect:!1},{text:"Keep specifications updated and refactor regularly",isCorrect:!0},{text:"Delete and regenerate everything monthly",isCorrect:!1},{text:"Only fix critical bugs, ignore everything else",isCorrect:!1}],explanation:"Maintain AI-generated code by keeping specifications current, documenting with human explanations, refactoring regularly, conducting code reviews, and updating as AI models improve."},{question:"What is the role of human oversight in AI-driven development?",options:[{text:"Humans are completely unnecessary",isCorrect:!1},{text:"Humans review, validate, and make critical architectural decisions",isCorrect:!0},{text:"Humans only write documentation",isCorrect:!1},{text:"Humans are only needed for deployment",isCorrect:!1}],explanation:"Human oversight remains crucial for reviewing code, validating against requirements, making architectural decisions, ensuring security, and maintaining code quality. AI assists but doesn't replace human judgment."}]}},4901:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>p,contentTitle:()=>d,default:()=>m,frontMatter:()=>l,metadata:()=>i,toc:()=>u});const i=JSON.parse('{"id":"chapters/implementation","title":"Chapter 8: Implementation Guide","description":"Setting Up Your Development Environment","source":"@site/docs/chapters/04-implementation.md","sourceDirName":"chapters","slug":"/chapters/implementation","permalink":"/ai-driven-book/docs/chapters/implementation","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":8,"frontMatter":{"sidebar_position":8,"id":"implementation","slug":"/chapters/implementation","title":"Chapter 8: Implementation Guide"},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 7: RAG Chatbots","permalink":"/ai-driven-book/docs/chapters/03-rag-chatbots"},"next":{"title":"\ud83d\udcda Resources","permalink":"/ai-driven-book/docs/resources"}}');var s=n(4848),o=n(8453),r=n(8440),a=n(7010),c=n(4442);const l={sidebar_position:8,id:"implementation",slug:"/chapters/implementation",title:"Chapter 8: Implementation Guide"},d="Chapter 8: Implementation Guide",p={},u=[{value:"Setting Up Your Development Environment",id:"setting-up-your-development-environment",level:2},{value:"Required Tools",id:"required-tools",level:3},{value:"API Keys Setup",id:"api-keys-setup",level:3},{value:"Building the Complete System",id:"building-the-complete-system",level:2},{value:"Project Structure",id:"project-structure",level:3},{value:"Backend Implementation",id:"backend-implementation",level:3},{value:"Dependencies",id:"dependencies",level:4},{value:"Configuration",id:"configuration",level:4},{value:"Document Ingestion Script",id:"document-ingestion-script",level:4},{value:"Frontend Implementation",id:"frontend-implementation",level:3},{value:"Install ChatKit",id:"install-chatkit",level:4},{value:"Create Chatbot Component",id:"create-chatbot-component",level:4},{value:"Styles",id:"styles",level:4},{value:"Integrate into Docusaurus",id:"integrate-into-docusaurus",level:4},{value:"Docker Deployment",id:"docker-deployment",level:3},{value:"Backend Dockerfile",id:"backend-dockerfile",level:4},{value:"Docker Compose",id:"docker-compose",level:4},{value:"Testing the System",id:"testing-the-system",level:2},{value:"Test Backend",id:"test-backend",level:3},{value:"Test Frontend",id:"test-frontend",level:3},{value:"Test Chatbot",id:"test-chatbot",level:3},{value:"Optimization Tips",id:"optimization-tips",level:2},{value:"Performance",id:"performance",level:3},{value:"Accuracy",id:"accuracy",level:3},{value:"Cost",id:"cost",level:3},{value:"Summary",id:"summary",level:2},{value:"\ud83d\udee0\ufe0f Implementation Workflow",id:"\ufe0f-implementation-workflow",level:2},{value:"\ud83d\udcdd Chapter Quiz",id:"-chapter-quiz",level:2}];function h(e){const t={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,o.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.header,{children:(0,s.jsx)(t.h1,{id:"chapter-8-implementation-guide",children:"Chapter 8: Implementation Guide"})}),"\n","\n",(0,s.jsx)("div",{style:{textAlign:"center",margin:"3rem 0"},children:(0,s.jsx)("img",{src:"/ai-driven-book/img/rocket-launch.svg",alt:"Implementation Guide",style:{maxWidth:"450px",width:"100%",height:"auto",filter:"drop-shadow(0 4px 12px rgba(0, 102, 255, 0.15))"}})}),"\n",(0,s.jsx)(t.h2,{id:"setting-up-your-development-environment",children:"Setting Up Your Development Environment"}),"\n",(0,s.jsx)(t.h3,{id:"required-tools",children:"Required Tools"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"# Node.js and npm\nnode --version  # v20+\nnpm --version   # v10+\n\n# Python\npython --version  # v3.9+\npip --version\n\n# Git\ngit --version\n\n# Docker (optional)\ndocker --version\n"})}),"\n",(0,s.jsx)(t.h3,{id:"api-keys-setup",children:"API Keys Setup"}),"\n",(0,s.jsxs)(t.p,{children:["Create a ",(0,s.jsx)(t.code,{children:".env"})," file:"]}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"# OpenAI\nOPENAI_API_KEY=sk-...\n\n# Qdrant Cloud\nQDRANT_URL=https://xxxxx.qdrant.io\nQDRANT_API_KEY=...\nQDRANT_COLLECTION=book_knowledge\n\n# Application\nPORT=8000\nENVIRONMENT=development\n"})}),"\n",(0,s.jsx)(t.h2,{id:"building-the-complete-system",children:"Building the Complete System"}),"\n",(0,s.jsx)(t.h3,{id:"project-structure",children:"Project Structure"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{children:"ai-driven-book/\n\u251c\u2500\u2500 frontend/              # Docusaurus site\n\u2502   \u251c\u2500\u2500 docs/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 static/\n\u2502   \u2514\u2500\u2500 docusaurus.config.ts\n\u251c\u2500\u2500 backend/               # FastAPI server\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 scripts/               # Utility scripts\n\u2502   \u2514\u2500\u2500 ingest_docs.py\n\u2514\u2500\u2500 docker-compose.yml\n"})}),"\n",(0,s.jsx)(t.h3,{id:"backend-implementation",children:"Backend Implementation"}),"\n",(0,s.jsx)(t.h4,{id:"dependencies",children:"Dependencies"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-txt",children:"# requirements.txt\nfastapi==0.104.1\nuvicorn[standard]==0.24.0\nopenai==1.3.0\nqdrant-client==1.7.0\npydantic==2.5.0\npydantic-settings==2.1.0\npython-multipart==0.0.6\npython-dotenv==1.0.0\n"})}),"\n",(0,s.jsx)(t.h4,{id:"configuration",children:"Configuration"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# app/config.py\nfrom pydantic_settings import BaseSettings\n\nclass Settings(BaseSettings):\n    # API Keys\n    OPENAI_API_KEY: str\n    QDRANT_URL: str\n    QDRANT_API_KEY: str\n    QDRANT_COLLECTION: str = "book_knowledge"\n\n    # Application\n    PORT: int = 8000\n    ENVIRONMENT: str = "development"\n    CORS_ORIGINS: list[str] = ["http://localhost:3000"]\n\n    class Config:\n        env_file = ".env"\n\nsettings = Settings()\n'})}),"\n",(0,s.jsx)(t.h4,{id:"document-ingestion-script",children:"Document Ingestion Script"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-python",children:'# scripts/ingest_docs.py\nimport os\nimport asyncio\nfrom pathlib import Path\nfrom qdrant_client import AsyncQdrantClient\nfrom qdrant_client.models import Distance, VectorParams, PointStruct\nfrom openai import AsyncOpenAI\nimport uuid\n\nasync def ingest_docusaurus_docs():\n    """Ingest all Docusaurus markdown files"""\n\n    # Initialize clients\n    openai = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))\n    qdrant = AsyncQdrantClient(\n        url=os.getenv("QDRANT_URL"),\n        api_key=os.getenv("QDRANT_API_KEY")\n    )\n\n    collection_name = "book_knowledge"\n\n    # Create collection\n    try:\n        await qdrant.create_collection(\n            collection_name=collection_name,\n            vectors_config=VectorParams(\n                size=1536,\n                distance=Distance.COSINE\n            )\n        )\n        print(f"Created collection: {collection_name}")\n    except Exception as e:\n        print(f"Collection exists or error: {e}")\n\n    # Find all markdown files\n    docs_path = Path("../frontend/docs")\n    md_files = list(docs_path.rglob("*.md")) + list(docs_path.rglob("*.mdx"))\n\n    print(f"Found {len(md_files)} markdown files")\n\n    points = []\n\n    for md_file in md_files:\n        print(f"Processing {md_file}...")\n\n        # Read content\n        content = md_file.read_text(encoding="utf-8")\n\n        # Remove frontmatter\n        if content.startswith("---"):\n            parts = content.split("---", 2)\n            if len(parts) >= 3:\n                content = parts[2].strip()\n\n        # Chunk document\n        chunks = chunk_document(content)\n\n        # Create embeddings\n        for i, chunk in enumerate(chunks):\n            if len(chunk.strip()) < 50:  # Skip very small chunks\n                continue\n\n            # Get embedding\n            response = await openai.embeddings.create(\n                model="text-embedding-3-small",\n                input=chunk\n            )\n            embedding = response.data[0].embedding\n\n            # Create point\n            point = PointStruct(\n                id=str(uuid.uuid4()),\n                vector=embedding,\n                payload={\n                    "text": chunk,\n                    "source": str(md_file.relative_to(docs_path)),\n                    "chunk_index": i,\n                    "file_path": str(md_file)\n                }\n            )\n            points.append(point)\n\n        print(f"  Created {len(chunks)} chunks")\n\n    # Upload to Qdrant\n    print(f"\\nUploading {len(points)} points to Qdrant...")\n    await qdrant.upsert(\n        collection_name=collection_name,\n        points=points\n    )\n\n    print("Ingestion complete!")\n\ndef chunk_document(text: str, chunk_size: int = 1000, overlap: int = 200) -> list[str]:\n    """Split document into overlapping chunks"""\n    chunks = []\n    start = 0\n\n    while start < len(text):\n        end = start + chunk_size\n        chunk = text[start:end]\n\n        # Try to break at paragraph or sentence\n        if end < len(text):\n            # Look for paragraph break\n            last_para = chunk.rfind(\'\\n\\n\')\n            if last_para > chunk_size * 0.5:\n                end = start + last_para\n            else:\n                # Look for sentence break\n                last_period = chunk.rfind(\'.\')\n                if last_period > chunk_size * 0.7:\n                    end = start + last_period + 1\n\n            chunk = text[start:end]\n\n        if chunk.strip():\n            chunks.append(chunk.strip())\n\n        start = end - overlap\n\n    return chunks\n\nif __name__ == "__main__":\n    asyncio.run(ingest_docusaurus_docs())\n'})}),"\n",(0,s.jsx)(t.h3,{id:"frontend-implementation",children:"Frontend Implementation"}),"\n",(0,s.jsx)(t.h4,{id:"install-chatkit",children:"Install ChatKit"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"cd frontend\nnpm install @openai/chatkit\n"})}),"\n",(0,s.jsx)(t.h4,{id:"create-chatbot-component",children:"Create Chatbot Component"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:"// src/components/Chatbot/index.tsx\nimport React, { useState } from 'react';\nimport styles from './styles.module.css';\n\ninterface Message {\n  role: 'user' | 'assistant';\n  content: string;\n  sources?: Array<{ text: string; score: number }>;\n}\n\nexport default function Chatbot() {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [input, setInput] = useState('');\n  const [isLoading, setIsLoading] = useState(false);\n  const [selectedText, setSelectedText] = useState('');\n\n  // Listen for text selection\n  React.useEffect(() => {\n    const handleSelection = () => {\n      const selection = window.getSelection();\n      const text = selection?.toString().trim();\n      if (text && text.length > 10) {\n        setSelectedText(text);\n      }\n    };\n\n    document.addEventListener('mouseup', handleSelection);\n    return () => document.removeEventListener('mouseup', handleSelection);\n  }, []);\n\n  const sendMessage = async () => {\n    if (!input.trim()) return;\n\n    const userMessage: Message = { role: 'user', content: input };\n    setMessages(prev => [...prev, userMessage]);\n    setInput('');\n    setIsLoading(true);\n\n    try {\n      const response = await fetch('http://localhost:8000/api/chat', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          message: input,\n          context: selectedText || null\n        })\n      });\n\n      const data = await response.json();\n\n      const assistantMessage: Message = {\n        role: 'assistant',\n        content: data.response,\n        sources: data.sources\n      };\n\n      setMessages(prev => [...prev, assistantMessage]);\n      setSelectedText(''); // Clear selection after use\n    } catch (error) {\n      console.error('Error:', error);\n      setMessages(prev => [...prev, {\n        role: 'assistant',\n        content: 'Sorry, I encountered an error. Please try again.'\n      }]);\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  return (\n    <div className={styles.chatbot}>\n      {selectedText && (\n        <div className={styles.contextBanner}>\n          Context selected: \"{selectedText.substring(0, 50)}...\"\n          <button onClick={() => setSelectedText('')}>Clear</button>\n        </div>\n      )}\n\n      <div className={styles.messages}>\n        {messages.map((msg, idx) => (\n          <div key={idx} className={styles[msg.role]}>\n            <div className={styles.content}>{msg.content}</div>\n            {msg.sources && msg.sources.length > 0 && (\n              <div className={styles.sources}>\n                <strong>Sources:</strong>\n                {msg.sources.map((source, i) => (\n                  <div key={i} className={styles.source}>\n                    {source.text} (relevance: {(source.score * 100).toFixed(1)}%)\n                  </div>\n                ))}\n              </div>\n            )}\n          </div>\n        ))}\n        {isLoading && <div className={styles.loading}>Thinking...</div>}\n      </div>\n\n      <div className={styles.input}>\n        <input\n          type=\"text\"\n          value={input}\n          onChange={e => setInput(e.target.value)}\n          onKeyPress={e => e.key === 'Enter' && sendMessage()}\n          placeholder={\n            selectedText\n              ? \"Ask about the selected text...\"\n              : \"Ask a question about the book...\"\n          }\n        />\n        <button onClick={sendMessage} disabled={!input.trim() || isLoading}>\n          Send\n        </button>\n      </div>\n    </div>\n  );\n}\n"})}),"\n",(0,s.jsx)(t.h4,{id:"styles",children:"Styles"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-css",children:"/* src/components/Chatbot/styles.module.css */\n.chatbot {\n  position: fixed;\n  bottom: 20px;\n  right: 20px;\n  width: 400px;\n  height: 600px;\n  background: white;\n  border-radius: 10px;\n  box-shadow: 0 4px 20px rgba(0, 0, 0, 0.15);\n  display: flex;\n  flex-direction: column;\n  z-index: 1000;\n}\n\n.contextBanner {\n  background: #e3f2fd;\n  padding: 10px;\n  font-size: 12px;\n  border-bottom: 1px solid #90caf9;\n  display: flex;\n  justify-content: space-between;\n  align-items: center;\n}\n\n.contextBanner button {\n  background: #1976d2;\n  color: white;\n  border: none;\n  padding: 4px 8px;\n  border-radius: 4px;\n  cursor: pointer;\n}\n\n.messages {\n  flex: 1;\n  overflow-y: auto;\n  padding: 20px;\n}\n\n.user, .assistant {\n  margin-bottom: 16px;\n  padding: 12px;\n  border-radius: 8px;\n}\n\n.user {\n  background: #e3f2fd;\n  margin-left: 40px;\n}\n\n.assistant {\n  background: #f5f5f5;\n  margin-right: 40px;\n}\n\n.content {\n  margin-bottom: 8px;\n}\n\n.sources {\n  font-size: 12px;\n  color: #666;\n  margin-top: 8px;\n  padding-top: 8px;\n  border-top: 1px solid #ddd;\n}\n\n.source {\n  margin-top: 4px;\n  padding: 4px;\n  background: white;\n  border-radius: 4px;\n}\n\n.loading {\n  text-align: center;\n  color: #666;\n  font-style: italic;\n}\n\n.input {\n  display: flex;\n  padding: 16px;\n  border-top: 1px solid #eee;\n}\n\n.input input {\n  flex: 1;\n  padding: 10px;\n  border: 1px solid #ddd;\n  border-radius: 4px;\n  margin-right: 8px;\n}\n\n.input button {\n  padding: 10px 20px;\n  background: #1976d2;\n  color: white;\n  border: none;\n  border-radius: 4px;\n  cursor: pointer;\n}\n\n.input button:disabled {\n  background: #ccc;\n  cursor: not-allowed;\n}\n"})}),"\n",(0,s.jsx)(t.h4,{id:"integrate-into-docusaurus",children:"Integrate into Docusaurus"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-typescript",children:"// src/theme/Root.tsx\nimport React from 'react';\nimport Chatbot from '../components/Chatbot';\n\nexport default function Root({ children }) {\n  return (\n    <>\n      {children}\n      <Chatbot />\n    </>\n  );\n}\n"})}),"\n",(0,s.jsx)(t.h3,{id:"docker-deployment",children:"Docker Deployment"}),"\n",(0,s.jsx)(t.h4,{id:"backend-dockerfile",children:"Backend Dockerfile"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-dockerfile",children:'# backend/Dockerfile\nFROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY app/ ./app/\n\nEXPOSE 8000\n\nCMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]\n'})}),"\n",(0,s.jsx)(t.h4,{id:"docker-compose",children:"Docker Compose"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-yaml",children:'# docker-compose.yml\nversion: \'3.8\'\n\nservices:\n  backend:\n    build: ./backend\n    ports:\n      - "8000:8000"\n    env_file:\n      - ./backend/.env\n    environment:\n      - PORT=8000\n    restart: unless-stopped\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    ports:\n      - "3000:3000"\n    depends_on:\n      - backend\n    restart: unless-stopped\n'})}),"\n",(0,s.jsx)(t.h2,{id:"testing-the-system",children:"Testing the System"}),"\n",(0,s.jsx)(t.h3,{id:"test-backend",children:"Test Backend"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"cd backend\npython -m venv venv\nsource venv/bin/activate  # Windows: venv\\Scripts\\activate\npip install -r requirements.txt\nuvicorn app.main:app --reload\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Visit ",(0,s.jsx)(t.code,{children:"http://localhost:8000/docs"})," for API documentation."]}),"\n",(0,s.jsx)(t.h3,{id:"test-frontend",children:"Test Frontend"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-bash",children:"cd frontend\nnpm install\nnpm start\n"})}),"\n",(0,s.jsxs)(t.p,{children:["Visit ",(0,s.jsx)(t.code,{children:"http://localhost:3000"})]}),"\n",(0,s.jsx)(t.h3,{id:"test-chatbot",children:"Test Chatbot"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsx)(t.li,{children:"Select some text on the page"}),"\n",(0,s.jsx)(t.li,{children:"Ask a question in the chatbot"}),"\n",(0,s.jsx)(t.li,{children:"Verify it uses the selected context"}),"\n",(0,s.jsx)(t.li,{children:"Try asking without selection"}),"\n",(0,s.jsx)(t.li,{children:"Check source citations"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"optimization-tips",children:"Optimization Tips"}),"\n",(0,s.jsx)(t.h3,{id:"performance",children:"Performance"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Cache embeddings"})," - Don't regenerate for same text"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Batch processing"})," - Process multiple documents at once"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Async operations"})," - Use async/await throughout"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Connection pooling"})," - Reuse database connections"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"accuracy",children:"Accuracy"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Chunk size tuning"})," - Experiment with 500-2000 characters"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Overlap adjustment"})," - 10-20% overlap prevents context loss"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Retrieval tuning"})," - Adjust top_k based on query complexity"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Prompt engineering"})," - Refine system prompts for better responses"]}),"\n"]}),"\n",(0,s.jsx)(t.h3,{id:"cost",children:"Cost"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Use smaller models"})," - text-embedding-3-small is cheaper"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Cache responses"})," - Store common queries"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Optimize chunk count"})," - Fewer chunks = lower storage costs"]}),"\n",(0,s.jsxs)(t.li,{children:[(0,s.jsx)(t.strong,{children:"Rate limiting"})," - Prevent abuse"]}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"summary",children:"Summary"}),"\n",(0,s.jsx)(t.p,{children:"In this chapter, you implemented:"}),"\n",(0,s.jsxs)(t.ul,{children:["\n",(0,s.jsx)(t.li,{children:"Complete FastAPI backend with RAG"}),"\n",(0,s.jsx)(t.li,{children:"Document ingestion pipeline"}),"\n",(0,s.jsx)(t.li,{children:"Docusaurus chatbot integration"}),"\n",(0,s.jsx)(t.li,{children:"Text selection context feature"}),"\n",(0,s.jsx)(t.li,{children:"Docker deployment configuration"}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Next Chapter:"})," Advanced topics including multi-agent systems and custom Claude Code skills."]}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"\ufe0f-implementation-workflow",children:"\ud83d\udee0\ufe0f Implementation Workflow"}),"\n",(0,s.jsx)(r.A,{title:"AI-Assisted Implementation Process",diagram:"graph TD\n  Spec[\ud83d\udccb Specification] --\x3e Prompt[\u270d\ufe0f Craft Prompt]\n  Prompt --\x3e AI[\ud83e\udd16 AI Generation]\n  AI --\x3e Code[\ud83d\udcbb Generated Code]\n  Code --\x3e Review{\ud83d\udc40 Review}\n\n  Review --\x3e|Issues| Refine[\ud83d\udd27 Refine Prompt]\n  Refine --\x3e AI\n\n  Review --\x3e|Good| Test[\u2705 Write Tests]\n  Test --\x3e Run{\ud83e\uddea Tests Pass?}\n\n  Run --\x3e|Fail| Debug[\ud83d\udc1b Debug]\n  Debug --\x3e AI\n\n  Run --\x3e|Pass| Deploy[\ud83d\ude80 Deploy]\n\n  style Spec fill:#ff4757,stroke:#2f3542,stroke-width:3px\n  style Prompt fill:#ffa502,stroke:#2f3542,stroke-width:3px\n  style AI fill:#ffd700,stroke:#2f3542,stroke-width:3px\n  style Code fill:#00d2d3,stroke:#2f3542,stroke-width:3px\n  style Review fill:#5352ed,stroke:#2f3542,stroke-width:3px\n  style Refine fill:#ff6348,stroke:#2f3542,stroke-width:3px\n  style Test fill:#2ed573,stroke:#2f3542,stroke-width:3px\n  style Run fill:#1e90ff,stroke:#2f3542,stroke-width:3px\n  style Debug fill:#ff7675,stroke:#2f3542,stroke-width:3px\n  style Deploy fill:#00b894,stroke:#2f3542,stroke-width:3px",caption:"Step-by-step implementation process with AI assistance."}),"\n",(0,s.jsx)(t.p,{children:"\\n## \ud83c\udfb4 Test Your Knowledge"}),"\n","\n",(0,s.jsx)(a.A,{cards:a.d.ch4,title:"Chapter Flashcards"}),"\n",(0,s.jsx)(t.hr,{}),"\n",(0,s.jsx)(t.h2,{id:"-chapter-quiz",children:"\ud83d\udcdd Chapter Quiz"}),"\n","\n",(0,s.jsx)(c.A,{questions:c.f.ch8,title:"Chapter 8 Quiz"}),"\n",(0,s.jsx)(t.hr,{})]})}function m(e={}){const{wrapper:t}={...(0,o.R)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);